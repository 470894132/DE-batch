{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9a1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>JobType</th>\n",
       "      <th>EdType</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>nativecountry</th>\n",
       "      <th>SalStat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>United-States</td>\n",
       "      <td>less than or equal to 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>less than or equal to 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>greater than 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>less than or equal to 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>less than or equal to 50,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       JobType         EdType        maritalstatus       occupation  \\\n",
       "0   45       Private        HS-grad             Divorced     Adm-clerical   \n",
       "1   24   Federal-gov        HS-grad        Never-married     Armed-Forces   \n",
       "2   44       Private   Some-college   Married-civ-spouse   Prof-specialty   \n",
       "3   27       Private            9th        Never-married     Craft-repair   \n",
       "4   20       Private   Some-college        Never-married            Sales   \n",
       "\n",
       "      relationship    race   gender  capitalgain  capitalloss  hoursperweek  \\\n",
       "0    Not-in-family   White   Female            0            0            28   \n",
       "1        Own-child   White     Male            0            0            40   \n",
       "2          Husband   White     Male            0            0            40   \n",
       "3   Other-relative   White     Male            0            0            40   \n",
       "4    Not-in-family   White     Male            0            0            35   \n",
       "\n",
       "    nativecountry                        SalStat  \n",
       "0   United-States   less than or equal to 50,000  \n",
       "1   United-States   less than or equal to 50,000  \n",
       "2   United-States            greater than 50,000  \n",
       "3          Mexico   less than or equal to 50,000  \n",
       "4   United-States   less than or equal to 50,000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "income = pd.read_csv(\"C:/Users/47089/OneDrive/Desktop/marlabs/income.csv\")\n",
    "\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd40dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_model_prep(data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    data = pd.get_dummies(\n",
    "        data.assign(\n",
    "            target = np.where(data[\"SalStat\"] == \" less than or equal to 50,000\", 0, 1),\n",
    "            nativecountry = data[\"nativecountry\"].replace({\" Holand-Netherlands\": \" Germany\"}),\n",
    "            occupation = data[\"occupation\"].replace({\" Armed-Forces\": \" ?\"}),\n",
    "            JobType = data[\"JobType\"].replace({\" Never-worked\": \" Without-pay\"}),\n",
    "        ).drop(\"SalStat\", axis=1), \n",
    "        drop_first=True\n",
    "    )\n",
    "    X = data.drop(\"target\", axis=1)\n",
    "    y = data[\"target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e61027",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = income_model_prep(income) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ccd3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8539712320200125\n",
      "F1: 0.6652329749103942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy: {lr.score(X_test, y_test)}\")\n",
    "print(f\"F1: {f1_score(y_test, lr.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcc933",
   "metadata": {},
   "source": [
    "## Assignment 1: Sampling Methods\n",
    "\n",
    "The following steps can be done one by one or in a single cell.\n",
    "\n",
    "1. Undersample the data to a 2:1 ratio of 0s to 1s and fit a logistic regression - generate a confusion matrix and calculate common evaluation metrics (Accuracy, Precision Recall, F1). \n",
    "\n",
    "2. Oversample the data using random oversampling.Create 4x the the current number of 1s. and fit a logistic regression - generate a confusion matrix and calculate common evaluation metrics. \n",
    "\n",
    "3. Use SMOTE to oversample the data. Create 4x the the current number of 1s. Fit a logistic regression and generate a confusion matrix, as well as calculate common evaluation metrics. \n",
    "\n",
    "4. Which model sampling approach best for this data? Pick the one that gave the best performance at the default threshold, then tune the threshold and report optimized F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85cb0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn.under_sampling as US, imblearn.over_sampling as OS\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27eebeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4324  557]\n",
      " [ 424 1091]]\n",
      "Accuracy:  0.8466228893058161\n",
      "Precision:  0.6620145631067961\n",
      "Recall:  0.7201320132013201\n",
      "F1 score:  0.6898514068921909\n"
     ]
    }
   ],
   "source": [
    "# Undersample:\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "#print(n_pos, n_neg)\n",
    "minority_pct = 1/3\n",
    "RUS = US.RandomUnderSampler(\n",
    "    sampling_strategy = (minority_pct) / (1-minority_pct),\n",
    "    random_state = 101\n",
    ")\n",
    "\n",
    "X_train_rs, y_train_rs = RUS.fit_resample(X_train, y_train)\n",
    "# print(np.mean(y_train))\n",
    "# print(np.mean(y_train_rs))\n",
    "lr_us = LogisticRegression(max_iter=5000)\n",
    "lr_us.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, lr_us.predict(X_test)))\n",
    "print('Accuracy: ', lr_us.score(X_test, y_test))\n",
    "print('Precision: ', precision_score(y_test, lr_us.predict(X_test)))\n",
    "print('Recall: ', recall_score(y_test, lr_us.predict(X_test)))\n",
    "print('F1 score: ', f1_score(y_test, lr_us.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a379c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3648 1233]\n",
      " [ 150 1365]]\n",
      "Accuracy:  0.7837711069418386\n",
      "Precision:  0.5254041570438799\n",
      "Recall:  0.900990099009901\n",
      "F1 score:  0.6637490882567468\n"
     ]
    }
   ],
   "source": [
    "# Oversample:\n",
    "ratio = {1:n_pos * 4, 0:n_neg}\n",
    "ROS = OS.RandomOverSampler(\n",
    "    sampling_strategy = ratio,\n",
    "    random_state = 101\n",
    ")\n",
    "\n",
    "X_train_os, y_train_os = ROS.fit_resample(X_train, y_train)\n",
    "lr_os = LogisticRegression(max_iter=5000)\n",
    "lr_os.fit(X_train_os, y_train_os)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, lr_os.predict(X_test)))\n",
    "print('Accuracy: ', lr_os.score(X_test, y_test))\n",
    "print('Precision: ', precision_score(y_test, lr_os.predict(X_test)))\n",
    "print('Recall: ', recall_score(y_test, lr_os.predict(X_test)))\n",
    "print('F1 score: ', f1_score(y_test, lr_os.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9318b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4134  747]\n",
      " [ 378 1137]]\n",
      "Accuracy:  0.824108818011257\n",
      "Precision:  0.6035031847133758\n",
      "Recall:  0.7504950495049505\n",
      "F1 score:  0.6690203000882613\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "ratio = {1:n_pos * 4, 0:n_neg}\n",
    "smote = SMOTE(sampling_strategy = ratio)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "lr_smote = LogisticRegression(max_iter=5000)\n",
    "lr_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, lr_smote.predict(X_test)))\n",
    "print('Accuracy: ', lr_smote.score(X_test, y_test))\n",
    "print('Precision: ', precision_score(y_test, lr_smote.predict(X_test)))\n",
    "print('Recall: ', recall_score(y_test, lr_smote.predict(X_test)))\n",
    "print('F1 score: ', f1_score(y_test, lr_smote.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db6123",
   "metadata": {},
   "source": [
    "Since Undersample model has the highest F1 score, Undersample is best for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70a0de07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized F1 Score:  0.6943879034603082\n"
     ]
    }
   ],
   "source": [
    "# Tune the threshold\n",
    "f1 = []\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (lr_us.predict_proba(X_test)[:,1] > threshold)\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "print('Optimized F1 Score: ', max(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5cb24",
   "metadata": {},
   "source": [
    "## Assignment 2: Class Weights\n",
    "\n",
    "1. Fit a regression with standard, balanced and 4:1 (minority vs majority) class weights. Calculate the AUC for each.\n",
    "2. For the weighting that had the best AUC, tune the threshold to maximize F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb8a74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Standard:  0.9068523939056475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "\n",
    "# standard\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "lr.fit(X_train, y_train)\n",
    "auc_standard = roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1])\n",
    "print('AUC Standard: ', auc_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca435668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Balanced:  0.9068523939056475\n"
     ]
    }
   ],
   "source": [
    "# balanced\n",
    "lr_balanced = LogisticRegression(class_weight = 'balance', max_iter = 5000)\n",
    "lr_balanced.fit(X_train, y_train)\n",
    "auc_balanced = roc_auc_score(y_test, lr_balanced.predict_proba(X_test)[:, 1])\n",
    "print('AUC Balanced: ', auc_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8719f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 4x:  0.9090833115272192\n"
     ]
    }
   ],
   "source": [
    "# 4:1\n",
    "lr_4x = LogisticRegression(class_weight = {1:4, 0:1}, max_iter = 5000)\n",
    "lr_4x.fit(X_train, y_train)\n",
    "auc_4x = roc_auc_score(y_test, lr_4x.predict_proba(X_test)[:, 1])\n",
    "print('AUC 4x: ', auc_4x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0858639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized F1 Score: 0.7032710280373832\n"
     ]
    }
   ],
   "source": [
    "# Best F1 Score\n",
    "# lr_4x has the highest AUC\n",
    "p_curve, r_curve, t_curve = precision_recall_curve(y_test, lr_4x.predict_proba(X_test)[:, 1])\n",
    "f1 = 2 * r_curve * p_curve / (r_curve + p_curve)\n",
    "print('Optimized F1 Score:', max(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
